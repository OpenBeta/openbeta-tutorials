{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rytheranderson/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### Route Search\n",
    "* Routes can be searched based on similarity to phrases, while also subsetting for location, quality, type, grade, etc.\n",
    "* For example, the user could search for 13a sport routes with \"sustained crimps\" in their area and > 3 RQI.\n",
    "* This relies on quality (i.e. descriptive) descriptions, which some routes have and some don't.\n",
    "\n",
    "### Route Profiles\n",
    "* The doc2vec model can be used to create route profiles based on the route description similarity to keywords.\n",
    "* For example, similarity to \"crimp\", \"sloper\", \"jug\", etc. can be used to profile the holds of a route.\n",
    "* Style can also be profiled using keywords like \"sustained\", \"powerful\", \"thin\", etc.\n",
    "* I have gravitated towards using a word2vec model for this purpose, but the doc2vec model is another (similar) option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data, model, and key for accessing route IDs\n",
    "\n",
    "model = Doc2Vec.load('doc2vec.model')\n",
    "\n",
    "with open('docID_2_routeID.pkl', 'rb') as key:\n",
    "    routeID_key = pickle.load(key)\n",
    "    \n",
    "df = pd.read_pickle('Curated_OpenBetaAug2020_RytherAnderson.pkl.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning function, to clean input strings\n",
    "def clean_desc(desc):\n",
    "    \n",
    "    \"\"\"\n",
    "        cleans descriptions for use with doc2vec model\n",
    "    \"\"\"\n",
    "    \n",
    "    desc = str(desc).lower() # lowercase\n",
    "    desc = remove_stopwords(desc)\n",
    "    desc = re.sub(r'\\s+', ' ', desc) # multiple spaces converted to single spaces\n",
    "    desc = re.sub('[0-9]', '', desc) # remove digits\n",
    "    desc = re.sub(r'(?<=\\w)-(?=\\w)', ' ', desc) # dash replaced with space\n",
    "    desc = re.sub(f'[{re.escape(string.punctuation)}]', '', desc) # remove punctuation and special characters\n",
    "    \n",
    "    tokens = word_tokenize(desc)\n",
    "    tokens = [t for t in tokens if len(t) > 1] # remove short tokens\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# search function, compares to documents in the provided model\n",
    "def description_search(model, desc, routeID_key, route_data, topn=3):\n",
    "    \n",
    "    \"\"\"\n",
    "        model is the doc2vec model, desc is the description\n",
    "        returns all the data (contained in route_data) for the top N routes\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = clean_desc(desc)\n",
    "    inferred_vector = model.infer_vector(tokens, epochs=1000)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    route_data.route_ID = route_data.route_ID.astype(int)\n",
    "\n",
    "    for doc_id, score in sims:  # make sure the routes are in the correct order\n",
    "\n",
    "        route_id = routeID_key[doc_id]\n",
    "        route = route_data.query(f'route_ID == {route_id}').copy()\n",
    "        route['score'] = score\n",
    "        res = pd.concat([res, route])\n",
    "    \n",
    "    return res, [sim for dID, sim in sims], desc\n",
    "\n",
    "# writes out relevant data from a route search result, for testing\n",
    "def parse_search_results(res):\n",
    "    \n",
    "    \"\"\"\n",
    "        res is the output of the description search function\n",
    "    \"\"\"\n",
    "    \n",
    "    df, sims, desc = res\n",
    "    N = len(sims)\n",
    "    \n",
    "    print('Results for the following document:')\n",
    "    print()\n",
    "    print('\"' + desc + '\"')\n",
    "    print()\n",
    "    print(f'{N} routes returned')\n",
    "    for data, sim in zip([data for i, data in df.iterrows()], sims):\n",
    "        print('------------------------------------------------------------------------------------------------------------------------')\n",
    "        print('{:<40} {:<7} {:<5} {:<10}'.format('Name', 'Type', 'Grade', 'ID'))\n",
    "        grade = ' '.join([g for g in (data['YDS'], data['Vermin']) if g != None])\n",
    "        print('{:<40} {:<7} {:<5} {:<10}'.format(data['route_name'][0:40], data['type_string'], grade, data['route_ID']))\n",
    "        print()\n",
    "        print(f'DESCRIPTION (similarity = {np.round(sim,3)}):')\n",
    "        \n",
    "        desc = ' '.join(data['description'])\n",
    "        NC = len(desc)\n",
    "        ceil100 = math.ceil(NC/120)\n",
    "        \n",
    "        for i in range(ceil100):\n",
    "            print(desc[i*120:(i+1)*120])\n",
    "    print('------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the following document:\n",
      "\n",
      "\"Sustained pocket pulling, classic\"\n",
      "\n",
      "4 routes returned\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Cowgirl Paradise                         sport   5.11c 105850687 \n",
      "\n",
      "DESCRIPTION (similarity = 0.735):\n",
      "Good Pocket pulling.  Steep & sustained.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Ignorant Bliss                           sport   5.11b 113664798 \n",
      "\n",
      "DESCRIPTION (similarity = 0.733):\n",
      "Sustained pocket pulling. Excellent as part of the warmup for the other routes at the cliff.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Blue Suede Shoes                         sport   5.11d 108358024 \n",
      "\n",
      "DESCRIPTION (similarity = 0.731):\n",
      "Short but sustained pocket pulling along a face/arÃªte with spectacular views of the valley below. Quality.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "International Distress                   sport   5.11b 107191068 \n",
      "\n",
      "DESCRIPTION (similarity = 0.731):\n",
      "Perfect pocket pulling, the quintessential Spearfish climbing experience.  Limestone at it's finest.\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test some longer phrases\n",
    "\n",
    "test = [\n",
    "'Clean vertical face with small crimps',\n",
    "'Enduro climbing on jugs',\n",
    "'A long, thin finger crack',\n",
    "'This route may cause you to void your bowels',\n",
    "'Just a really massive dyno',\n",
    "'Lots of pinches',\n",
    "'Sustained pocket pulling, classic',\n",
    "'Big dyno to jug for cool people',\n",
    "]\n",
    "\n",
    "res = description_search(model, test[-2], routeID_key, df, topn=4)\n",
    "parse_search_results(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = {'route_data': df, 'routeID_key': routeID_key}\n",
    "\n",
    "with gzip.open('search_data.pkl.zip', 'wb') as out:\n",
    "    pickle.dump(search_data, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
