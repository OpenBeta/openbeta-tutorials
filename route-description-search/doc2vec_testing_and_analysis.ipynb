{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rytheranderson/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### Route Search\n",
    "* Routes can be searched based on similarity to phrases, while also subsetting for location, quality, type, grade, etc.\n",
    "* For example, the user could search for 13a sport routes with \"sustained crimps\" in their area and > 3 RQI.\n",
    "* This relies on quality (i.e. descriptive) descriptions, which some routes have and some don't.\n",
    "\n",
    "### Route Profiles\n",
    "* The doc2vec model can be used to create route profiles based on the route description similarity to keywords.\n",
    "* For example, similarity to \"crimp\", \"sloper\", \"jug\", etc. can be used to profile the holds of a route.\n",
    "* Style can also be profiled using keywords like \"sustained\", \"powerful\", \"thin\", etc.\n",
    "* I have gravitated towards using a word2vec model for this purpose, but the doc2vec model is another (similar) option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data, model, and key for accessing route IDs\n",
    "\n",
    "model = Doc2Vec.load('doc2vec.model')\n",
    "\n",
    "with open('docID_2_routeID.pkl', 'rb') as key:\n",
    "    routeID_key = pickle.load(key)\n",
    "    \n",
    "df = pd.read_pickle('Curated_OpenBetaAug2020_RytherAnderson.pkl.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning function, to clean input strings\n",
    "def clean_desc(desc):\n",
    "    \n",
    "    \"\"\"\n",
    "        cleans descriptions for use with doc2vec model\n",
    "    \"\"\"\n",
    "    \n",
    "    desc = str(desc).lower() # lowercase\n",
    "    desc = remove_stopwords(desc)\n",
    "    desc = re.sub(r'\\s+', ' ', desc) # multiple spaces converted to single spaces\n",
    "    desc = re.sub('[0-9]', '', desc) # remove digits\n",
    "    desc = re.sub(r'(?<=\\w)-(?=\\w)', ' ', desc) # dash replaced with space\n",
    "    desc = re.sub(f'[{re.escape(string.punctuation)}]', '', desc) # remove punctuation and special characters\n",
    "    \n",
    "    tokens = word_tokenize(desc)\n",
    "    tokens = [t for t in tokens if len(t) > 1] # remove short tokens\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# search function, compares to documents in the provided model\n",
    "def description_search(model, desc, routeID_key, route_data, topn=3):\n",
    "    \n",
    "    \"\"\"\n",
    "        model is the doc2vec model, desc is the description\n",
    "        returns all the data (contained in route_data) for the top N routes\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = clean_desc(desc)\n",
    "    inferred_vector = model.infer_vector(tokens, epochs=100)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "    data = route_data[route_data['route_ID'].isin([routeID_key[dID] for dID, sim in sims])].copy()\n",
    "    \n",
    "    return data, [sim for dID, sim in sims], desc\n",
    "\n",
    "# writes out relevant data from a route search result, for testing\n",
    "def parse_search_results(res):\n",
    "    \n",
    "    \"\"\"\n",
    "        res is the output of the description search function\n",
    "    \"\"\"\n",
    "    \n",
    "    df, sims, desc = res\n",
    "    N = len(sims)\n",
    "    \n",
    "    print('Results for the following document:')\n",
    "    print()\n",
    "    print('\"' + desc + '\"')\n",
    "    print()\n",
    "    print(f'{N} routes returned')\n",
    "    for data, sim in zip([data for i,data in df.iterrows()], sims):\n",
    "        print('------------------------------------------------------------------------------------------------------------------------')\n",
    "        print('{:<40} {:<7} {:<5} {:<10}'.format('Name', 'Type', 'Grade', 'ID'))\n",
    "        grade = ' '.join([g for g in (data['YDS'], data['Vermin']) if g != None])\n",
    "        print('{:<40} {:<7} {:<5} {:<10}'.format(data['route_name'][0:40], data['type_string'], grade, data['route_ID']))\n",
    "        print()\n",
    "        print(f'DESCRIPTION (similarity = {np.round(sim,3)}):')\n",
    "        \n",
    "        desc = ' '.join(data['description'])\n",
    "        NC = len(desc)\n",
    "        ceil100 = math.ceil(NC/120)\n",
    "        \n",
    "        formatted = []\n",
    "        for i in range(ceil100):\n",
    "            print(desc[i*120:(i+1)*120])\n",
    "    print('------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the following document:\n",
      "\n",
      "\"A big, scary, runout slab\"\n",
      "\n",
      "3 routes returned\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Ed's Arete Right                         boulder V5    107084467 \n",
      "\n",
      "DESCRIPTION (similarity = 0.784):\n",
      "On the main, huge, imposing highball boulder in the cluster (just off of the road to the right).  This is the right aret\n",
      "e of the main boulder face.  climb high prominent arete to the scary, sketchy, harder than it looks finish way off the d\n",
      "eck.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Bone Club, The                           trad    5.10b 105858738 \n",
      "\n",
      "DESCRIPTION (similarity = 0.766):\n",
      "a steep, slick face with a long, scary runout up to the first bolt\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Name                                     Type    Grade ID        \n",
      "Squirrel Roast                           trad    5.7   105860275 \n",
      "\n",
      "DESCRIPTION (similarity = 0.755):\n",
      "a fun, runout, exposed knobby face\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test some longer phrases\n",
    "\n",
    "TP0 = [\n",
    "'Clean vertical face with small crimps',\n",
    "'Follow perfect crimps and edges up the vertical face.',\n",
    "'Make a huge deadpoint off these jugs to a half pad crimp, match, and finish on jugs.',\n",
    "'A long, thin finger crack.',\n",
    "'This route may cause you to void your bowels.',\n",
    "'Just a really massive dyno.',\n",
    "'Thin face climb up the black streak. Follow sustained edges and crimps to the top.',\n",
    "'Compression up the refrigerator block to a big move at the lip.',\n",
    "'A big, scary, runout slab',\n",
    "'At the bulge, pull through the shouldery gaston crux to arrive at the chains.'\n",
    "]\n",
    "\n",
    "res = description_search(model, 'A big, scary, runout slab', routeID_key, df, topn=3)\n",
    "parse_search_results(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
